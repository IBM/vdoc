{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Document (VDoc) on SCROLLS datasets \n",
    "\n",
    "In this notebook we demonstrate how to run the vdoc code on the Qasper dataset ([Dasigi et al., 2021](https://arxiv.org/abs/2105.03011)) which is part of the SCROLLS suite ([Shaham et al. 2022](https://arxiv.org/abs/2201.03533)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "It is assumed that the user has already setup a Python 3.11 environment and installed the requirements in `requirements.txt` following the README file.\n",
    "\n",
    "In addition to that, we will need to install the Python package `wget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to make sure we have NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/yosimass/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Experimental Setup\n",
    "\n",
    "Here we define the configuration for our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scrolls base url\n",
    "scrolls_url = 'https://huggingface.co/datasets/tau/scrolls/resolve/main'\n",
    "\n",
    "# dataset name, file and split\n",
    "dataset_name = \"qasper\"\n",
    "dataset_zip_file = 'quality.zip'\n",
    "dataset_split = \"validation\"\n",
    "\n",
    "# vdoc settings\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_token_limit = 2400\n",
    "max_new_tokens = 0\n",
    "passage_len = 512\n",
    "order = \"doc\"\n",
    "queries_limit=500\n",
    "\n",
    "# input and output\n",
    "import os\n",
    "input_file = os.path.join(dataset_name, dataset_zip_file[:dataset_zip_file.index(\".\")], f\"{dataset_split}.jsonl\")\n",
    "output_file = os.path.join(dataset_name, \"output.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn to downloading Qasper from [SCROLLS](https://www.scrolls-benchmark.com/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 31252462 / 31252462"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "\n",
    "\n",
    "wget.download(f\"{scrolls_url}/{dataset_zip_file}\")\n",
    "with zipfile.ZipFile(dataset_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a VDoc experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/yosimass/.pyenv/versions/3.11.10/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/yosimass/.pyenv/versions/3.11.10/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/yosimass/.pyenv/versions/3.11.10/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/j5/07d3c4wj0jz1yv9vfp574dkw0000gn/T/ipykernel_82414/3545851111.py\", line 1, in <module>\n",
      "    from vdoc_eval import vdoc\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc/vdoc_eval.py\", line 5, in <module>\n",
      "    from create_virtual_document import VirtualDocument\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc/create_virtual_document.py\", line 8, in <module>\n",
      "    from rankers.tokenizer_utils import TokenizerUtils\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc/rankers/tokenizer_utils.py\", line 3, in <module>\n",
      "    from transformers import AutoTokenizer\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/yosimass/PycharmProjects/vdoc_paper/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7121 > 512). Running this sequence through the model will result in indexing errors\n",
      "2024-12-29 11:49:04,765 - vdoc_eval - INFO - Processing 100\n",
      "2024-12-29 11:49:22,784 - vdoc_eval - INFO - Processing 200\n",
      "2024-12-29 11:49:41,085 - vdoc_eval - INFO - Processing 300\n",
      "2024-12-29 11:49:58,478 - vdoc_eval - INFO - Processing 400\n",
      "2024-12-29 11:50:13,607 - vdoc_eval - INFO - Processing 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qasper/output.csv - Total count 500. bad documents 0. total vdoc 499. bad vdocs 0\n"
     ]
    }
   ],
   "source": [
    "from vdoc_eval import vdoc\n",
    "\n",
    "vdoc(dataset=\"scrolls\",\n",
    "     input_file=input_file,\n",
    "     output_file=output_file,\n",
    "     model_name=model_name,\n",
    "     model_token_limit=model_token_limit,\n",
    "     max_new_tokens=max_new_tokens,\n",
    "     passage_len=passage_len,\n",
    "     order=order,\n",
    "     queries_limit=queries_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
